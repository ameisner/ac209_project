Title of your project proposal
==============================
Video game reviews : classification and predicted ratings

Background and Motivation
Discuss your motivations and reasons for choosing this project, especially any
background or research interests that may have influenced your decision.
================================================================================
Since their inception, video games have been somewhat of a fringe cultural phenomenon. Not having the same aesthetic appeal as film or literature and not bearing the institutional legitimacy of more traditional games like chess, video games were considered for a long time awkwardly placed in the world of leisure activities.

But in the past decade with the development of new family oriented gaming consoles like the Wii, the creation of artistically rendered and presented games like Heavy Rain and The Last of Us, and the organization of pre-professional and competitive gaming societies, video games are slowly evolving from merely being the visual toys used exclusively by male teenagers to a new form of media which many demographics can use.  

The mediated reality potential video games make possible, only further ensures their relevance will continue to grow. And as this relevance grows, and the demand for a wider assortment of video games beyond the traditional action/adventure, role-playing game, shooter trifecta grows also, there will spring a larger need for video game criticism akin to that which exists for film and television today. 

Data scientists have a role in categorizing and understanding this criticism. By applying textual analysis techniques, we can determine whether a review is positive or negative. Not all online video game reviews are associated with a numerical weighting. By developing a text-rating classification scheme we will be able to determine what any online text related to a video game suggests about the quality of the video game. 



Project Objectives
What are the scientific and inferential goals for this project? What would you 
like to learn and accomplish? List the benefits.
================================================================================

The goal is to first determine whether its possible to classify the quality (colloquially constrained to be either ‘good’ or ‘bad’) of video games according to their text reviews. Second, we want to compare various classifiers and understand why certain classifiers are more accurate than others. 

As a first benefit, the project extends the domain of applicability of textual analysis from movie reviews  to video game reviews. As a secondary benefit, our methods could perhaps be adapted to more general contexts where the community opinion for a certain game could be determined by scraping together online text related to the game. This ‘opinion’ could then perhaps be used to pre-emptively gauge the potential demand for a game which has yet to be released. 



Must-Have Features
These are features or calculations without which you would consider your 
project to be a failure.
================================================================================




Optional Features
Those features or calculations which you consider would be nice to have, but 
not critical.
================================================================================

As part of our exploratory analysis we want to know what hidden variables can affect video game reviews. Some questions we want to answer include. 
	- Is there a time trend associated with video game reviews?
	- Do certain video game reviewers consistently give better or worse ratings than the average?
	- Do the same companies consistently produce high rating games? 



What Data?
From where and how are you collecting your data?
================================================
We have already gathered data from two sources. Our first source is the Giant 
Bomb video game website, which conveniently features APIs for published 
reviews, company information and user reviews. Giant Bomb review scores are 
integers, 1 (worst) through 5 (best). The Giant Bomb API is helpful in that
we can access review summaries, full review text and plenty of metadata for 
each game without scraping. The downside is that only 646 published reviews are
available via the API, which is likely insufficient given that we anticipate 
requiring a training set of several thousand review summaries. On the other 
hand, GameSpot has 13702 published reviews, but no API. We have therefore 
written a web scraper to gather all of the review summaries and corresponding 
scores for every GameSpot review published from 1996 to present. Although we 
now have these GameSpot review summaries and scores in hand, the lack of a 
GameSpot API makes gathering further metadata difficult/tedious. GameSpot 
review scores are more finely grained, ranging from 0 (worst) to 10 (best), 
including some non-integer scores.

The crucial data for our text classification are review summaries for published 
reviews (typically ~20 words) and their corresponding review scores. For each 
source of reviews, we already have gathered the summary text and scores. We 
will need to make a cut on the review scores from each source to split reviews 
into labels of "positive" and "negative".




Design Overview
List the statistical and computational methods you plan to use.
===============================================================
Our final analysis will center around applying and comparing various text 
sentiment classification techniques. For our baseline classification model, we 
will apply Naive Bayes classification to review summaries to predict whether a 
review is "positive" or "negative", in a manner analogous to that employed by 
last year's "Bayesian Tomatoes" assignment, including cross validation. 
Individual words will be used as features. We will also extend our baseline 
Naive Bayes classifier in several ways. One example would be to use the 
"stemming" technique from natural language processing to merge features which 
are the same in sentiment such that e.g. "awesomeness" and "awesome" would both
map to a single feature. Second, we could incorporate priors on e.g. reviewer, 
or game manufacturer during Naive Bayes classification. We also will attempt 
random forest classification for the sake of comparison. Time permitting, we 
may explore using n-grams as features rather than single words. In terms of 
predicting the scores of ratings, we will attempt to use k-nearest neighbors 
regression as a baseline, and attempt other regression methods as time permits.

Verification
How will you verify your project's results? In other words, how do you know 
that your project does well?
================================================================================




Visualization & Presentation
How will you visualize and communicate your results?
====================================================
Visualizations will be important at various stages in our analysis. First,
we will include exploratory visualizations near the beginning of our process
book to answer questions like: What is the distribution of review scores? What
is the time trend of the average review score over the years? What is the
average review score grouped by company, console, or reviewer? Such plots
would include basic histograms, line plots and bar charts.

Second, we will want to use visualizations to display our model calibration
results, similar to the "Bayesian Tomatoes" part 3.4 plots.

Finally, we will want to create a "take-home" visualization that illustrates
the results of our final classification analysis. One visualization we intend 
to make would be JavaScript word clouds of the most strongly positive and 
negative words, wherein mousing over each word deploys a tooltip showing 
P(good|word).


Schedule / timeline
Make sure that you plan your work so that you can avoid a big rush right before
the final project deadline, and delegate different modules and responsibilities
among your team members. Write this in terms of weekly deadlines.
=================================================================


